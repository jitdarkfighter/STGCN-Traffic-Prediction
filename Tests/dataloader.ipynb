{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4aaf43",
   "metadata": {},
   "source": [
    "# Understanding this weird dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da31b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6fd2f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shapes:\n",
      "Traffic data (V): (12671, 228)\n",
      "Adjacency matrix (W): (227, 228)\n",
      "\n",
      "Small dataset created:\n",
      "Traffic data: (12671, 4)\n",
      "Adjacency matrix: (4, 4)\n",
      "\n",
      "Sample traffic data (first 5 timesteps):\n",
      "   7.109999999999999432e+01  6.600000000000000000e+01  \\\n",
      "0                      68.1                      66.8   \n",
      "1                      68.0                      64.3   \n",
      "2                      68.3                      67.8   \n",
      "3                      68.9                      69.5   \n",
      "4                      66.6                      69.1   \n",
      "\n",
      "   6.459999999999999432e+01  6.559999999999999432e+01  \n",
      "0                      61.7                      66.7  \n",
      "1                      66.6                      68.7  \n",
      "2                      65.9                      66.6  \n",
      "3                      61.2                      67.4  \n",
      "4                      65.1                      65.2  \n",
      "\n",
      "Adjacency matrix:\n",
      "[[0.  1.  0.5 0. ]\n",
      " [1.  0.  1.  0.5]\n",
      " [0.5 1.  0.  1. ]\n",
      " [0.  0.5 1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "# print(\"Original dataset shapes:\")\n",
    "# print(f\"Traffic data (V): {dataset.shape}\")\n",
    "# print(f\"Adjacency matrix (W): {dataset2.shape}\")\n",
    "# print()\n",
    "\n",
    "# small_traffic = dataset.iloc[:, :4].copy()\n",
    "\n",
    "# small_adj = np.array([\n",
    "#     [0.0, 1.0, 0.5, 0.0],  # Node 0 connects to 1 and weakly to 2\n",
    "#     [1.0, 0.0, 1.0, 0.5],  # Node 1 connects to 0,2 and weakly to 3\n",
    "#     [0.5, 1.0, 0.0, 1.0],  # Node 2 connects to 1,3 and weakly to 0\n",
    "#     [0.0, 0.5, 1.0, 0.0]   # Node 3 connects to 2 and weakly to 1\n",
    "# ])\n",
    "\n",
    "# # Save the small dataset\n",
    "# small_traffic.to_csv(\"../dataset/V_small_4.csv\", index=False, header=False)\n",
    "# np.savetxt(\"../dataset/W_small_4.csv\", small_adj, delimiter=\",\", fmt='%.1f')\n",
    "\n",
    "# print(\"Small dataset created:\")\n",
    "# print(f\"Traffic data: {small_traffic.shape}\")\n",
    "# print(f\"Adjacency matrix: {small_adj.shape}\")\n",
    "# print()\n",
    "# print(\"Sample traffic data (first 5 timesteps):\")\n",
    "# print(small_traffic.head())\n",
    "# print()\n",
    "# print(\"Adjacency matrix:\")\n",
    "# print(small_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30fc0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"../dataset/V_small_4.csv\")\n",
    "dataset2 = pd.read_csv(r\"../dataset/W_small_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fa134f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset samples: 12656\n",
      "Batch X shape: torch.Size([64, 12, 4])\n",
      "Adjacency shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# === STGCN DataLoader Preparation ===\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Convert main traffic DataFrame to numpy: [time_steps, num_nodes]\n",
    "data_np = dataset.values\n",
    "\n",
    "# Define historical and prediction window lengths\n",
    "n_his, n_pred = 12, 3  # e.g., use past 12 steps to predict next 3\n",
    "\n",
    "class STGCNDataset(Dataset):\n",
    "    def __init__(self, data, his_len, pred_len):\n",
    "        self.data = data\n",
    "        self.his_len = his_len\n",
    "        self.pred_len = pred_len\n",
    "        self.num_samples = data.shape[0] - his_len - pred_len + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # input: [his_len, num_nodes]\n",
    "        x = self.data[idx : idx + self.his_len]\n",
    "        # target: [pred_len, num_nodes]\n",
    "        y = self.data[idx + self.his_len : idx + self.his_len + self.pred_len]\n",
    "        return torch.from_numpy(x).float(), torch.from_numpy(y).float()\n",
    "\n",
    "# Instantiate dataset and loader\n",
    "stgcn_dataset = STGCNDataset(data_np, n_his, n_pred)\n",
    "stgcn_loader = DataLoader(stgcn_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Load adjacency matrix (defines graph connectivity)\n",
    "w = dataset2.values\n",
    "adj = torch.from_numpy(w).float()  # shape: [num_nodes, num_nodes]\n",
    "\n",
    "# Inspect shapes\n",
    "print(f\"Dataset samples: {len(stgcn_dataset)}\")\n",
    "print(f\"Batch X shape: {next(iter(stgcn_loader))[0].shape}\")  # [batch, his_len, num_nodes]\n",
    "print(f\"Adjacency shape: {adj.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
